name: Nightly Retrain, Predictions, and Comparison

on:
  schedule:
    - cron: "0 13 * * *"   # every day at 6:00 UTC
  workflow_dispatch:

permissions:
  contents: write   # allow pushing commits

jobs:
  retrain_and_predict:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        model: [xgb, rf, logreg]

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4   

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4      
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Enrich schedule (with backup)
        run: |
          python -m src.scripts.enrich_schedule --season 2025 || echo "Schedule enrichment failed"
          mkdir -p data/backups
          cp data/cache/schedule.csv data/backups/schedule_backup_$(date +%F).csv || echo "No schedule file to back up"
          if [ -f data/cache/schedule.csv ]; then
            python -c "import pandas as pd; df=pd.read_csv('data/cache/schedule.csv'); df.to_parquet('data/cache/historical_schedule.parquet', index=False)"
          fi
        continue-on-error: true

      - name: Generate features (resilient)
        run: |
          python -m src.scripts.generate_features || echo "Feature generation failed"
          if [ ! -f data/cache/features_full.parquet ]; then
            mkdir -p data/cache
            python -c "import pandas as pd; pd.DataFrame(columns=['GAME_ID','SEASON','PTS','PTS_OPP','WL']).to_parquet('data/cache/features_full.parquet', index=False)"
            echo "Empty features file written"
          fi
        continue-on-error: true

      - name: Retrain ${{ matrix.model }} model
        run: |
          python -m src.model_training.trainer_cli \
            --model ${{ matrix.model }} \
            --season 2025 \
            --features data/cache/features_full.parquet \
            --out models/nba_${{ matrix.model }}.pkl \
            --metrics_out data/results/${{ matrix.model }}_metrics.csv \
            --importance_out data/results/${{ matrix.model }}_importance.csv

      - name: Generate predictions (only for xgb)
        if: matrix.model == 'xgb'
        run: |
          python -m src.prediction_engine.daily_runner_cli \
            --model models/nba_xgb.pkl \
            --season 2025 \
            --limit 10 \
            --out data/results/daily_predictions.csv \
            --fmt csv

      - name: Commit model artifacts
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
          git add models/nba_${{ matrix.model }}.pkl \
                 data/results/${{ matrix.model }}_metrics.csv \
                 data/results/${{ matrix.model }}_importance.csv \
                 data/cache/features_full.parquet || true
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: nightly retrain for ${{ matrix.model }}"
            git push
          fi

  aggregate_metrics:
    runs-on: ubuntu-latest
    needs: retrain_and_predict
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4   
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install pandas and tabulate
        run: pip install pandas tabulate

      - name: Aggregate metrics
        run: |
          mkdir -p data/results
          python - <<'EOF'
          import pandas as pd
          import glob
          from tabulate import tabulate
          files = glob.glob("data/results/*_metrics.csv")
          dfs = []
          for f in files:
              try:
                  df = pd.read_csv(f)
                  if not df.empty:
                      dfs.append(df)
              except Exception as e:
                  print(f"Skipping {f}: {e}")
          if dfs:
              combined = pd.concat(dfs, ignore_index=True)
              combined.to_csv("data/results/model_comparison.csv", index=False)
              print("\n=== Model Comparison Summary ===")
              print(tabulate(combined, headers="keys", tablefmt="github", showindex=False))
              print("================================\n")
              with open("data/results/model_comparison_summary.txt", "w") as f:
                  f.write(tabulate(combined, headers="keys", tablefmt="github", showindex=False))
          else:
              print("No metrics files found to aggregate")
          EOF

      - name: Commit aggregated comparison
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
          git add data/results/model_comparison.csv || true
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: nightly aggregated model comparison"
            git push

      - name: Upload summary artifact
        uses: actions/upload-artifact@v4   
        with:
          name: model-comparison-summary
          path: data/results/model_comparison_summary.txt
