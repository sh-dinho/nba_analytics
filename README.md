# NBA Prediction Pipeline

A Python pipeline for fetching NBA game data, generating features, training a logistic regression model, and producing daily win probability predictions. Outputs are saved locally in organized folders and can be connected directly to Power BI for dashboards.

---

## ğŸš€ How to Run

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Run the pipeline
```bash
  python run_pipeline.py
```
3. Outputs will be saved automatically into the data/ folder structure.
```bash
nba_project/
â”œâ”€ src/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ utils/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â”œâ”€ io.py
â”‚  â”‚   â”œâ”€ logging.py
â”‚  â”‚   â””â”€ nba_api_wrapper.py
â”‚  â”œâ”€ feature_engineering/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â””â”€ feature_engineering.py
â”‚  â”œâ”€ model_training/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â”œâ”€ train_logreg.py
â”‚  â”‚   â”œâ”€ train_xgb.py
â”‚  â”‚   â””â”€ training.py
â”‚  â”œâ”€ prediction_engine/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â””â”€ predictor.py
â”‚  â”œâ”€ interpretability/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â””â”€ shap_analysis.py
â”‚  â””â”€ main_today.py
â”œâ”€ data/
â”œâ”€ models/
â”œâ”€ results/
â””â”€ run_today.sh
```
4. Power Bi Integration
- Connect to Historical Prediction
  - Open Power BI Desktop
  - Go to Home -> Get Data -> Parquet
  - Select data/history/predictions_history.parquet
  - Load the table into Power BI.

5. Connect to Multiple Daily Files
  - Use the Folder connector:
    - for CSVs -> data/csv/
    - for Parquet -> data/parquet/
    - Load the table into Power BI

## Example Dashboards
  - Accuracy trend â†’ Line chart with prediction_date vs. accuracy.
  - Team analytics â†’ Bar chart with TEAM_ID vs. average pred_proba.
  - Game drill_downs â†’ Table with stats + predictions.

6. ğŸ›  Features- Data Quality Checks â†’ Validates critical columns, drops nulls, logs anomalies.
   - Error Handling â†’ Retries API calls with exponential backoff, logs errors separately.
   - Configurable â†’ Paths, seasons, and model path defined in config.yaml.
   - Environment Separation â†’ Raw, cache, history, CSV, Parquet, logs all in distinct folders.
   - Deduplication â†’ Unique IDs prevent duplicate rows.
   - Performance â†’ Batch feature generation speeds up initial fetch.
   - Unit Tests â†’ Core functions tested with pytest.

## ğŸ‘¥ Contributors- Developed in Python with â¤ï¸ for NBA analytics.
  - Designed for easy integration with Power BI.

## ğŸ“ˆ Roadmap- v1.0 â†’ Local Parquet/CSV storage, Power BI dashboards.
  - v2.0 â†’ Optional migration to SQLite/PostgreSQL for larger datasets.
  - Future â†’ Cloud integration (Azure Synapse, BigQuery, etc.).

## - Version 1.0 â†’ stick with logistic regression + clean pipeline (done).
    - Version 2.0 â†’ migrate storage to SQLite/Postgres.
    - Version 3.0 â†’ add AI models (XGBoost or neural nets) and integrate explainability.

![Coverage](https://img.shields.io/codecov/c/github/your-org/your-repo?style=flat-square)
